for (i in 1:nrow(genresListColumn)) {
for (c in 1:ncol(genresListColumn)) {
dummy_col = which(matrix_genre[1,] == genresListColumn[i,c])
matrix_genre[i+1,dummy_col] <- 1
}
}
matrix_genre [1:10,]# check the assigned values in matrix with values of genresListColumn.
summary(matrix_genre) # checking total rows
# convert data into data frame and removing first rows
matrix_genre_Removerow <- as.data.frame(matrix_genre[-1,], stringsAsFactors=FALSE) # we removed first row as we generated earlier for calculation purpose
summary(matrix_genre_Removerow) # checking rows count again
nrow(matrix_genre_Removerow) # no of rows
ncol(matrix_genre_Removerow) # no of columns
# convert matrix characters ["1" or "0"] to integers values [ 1 or 0] ----
for (c in 1:ncol(matrix_genre_Removerow)) {
matrix_genre_Removerow[,c] <- as.integer(matrix_genre_Removerow[,c])
}
summary(matrix_genre_Removerow) # check integer values in each column and check statistics
matrix_genre_Removerow[1:10,] # check first 10 rows of data set
movies_df <- cbind(as.data.frame(movies_d), matrix_genre_Removerow) # combine both column data (movie_d and matrix_genre_Removerow table)
head(movies_df) # checking first 10 records
# remove genres column from movie_df data sets ----
movies_df <- movies_df[,-3]
head(movies_df) # check first few rows
dim(movies_df) # check dimension
# creating year field in rating data as a new features ----
head(movies_df$title, 20) # check 1-20 rows of title
dim(movies_df) # check dimension
years=substr(movies_df$title, nchar(trimws(movies_df$title))-4, nchar(trimws(movies_df$title))-1) # pick year such as 1995 or 2005 (4 character) from the text string
year <- as.data.frame(years) # convert year field into data frame
movies_dfc <- cbind(movies_df, year) # combine both data (rating and year table)
head(movies_dfc,10) # check 1-10 rows
dim(movies_dfc) # check dimension
# searching 1 to 10 Crime movies by selecting year 2005 to find movie title ----
subset(movies_dfc, Crime == 1 & years == 2005)$title[1:10]
# searching 1 to 10 Horror movie by selecting year 1995 to find movie title ----
subset(movies_dfc, Horror == 1 & years == 1995)$title[1:10]
# remove timestamp from rating data set ----
head(ratings_d) # check rows
ratings_d <- ratings_d[,-4] # removing timestamp column
head(ratings_d) # check rows
dim(ratings_d) # check dimension
ratings_df<-as.data.frame(ratings_d) # convert rating data into data frame
dim(ratings_df) # check dimension
summary(ratings_df) # check statistic
head(ratings_df) # check few records
length(unique(ratings_df$movieId)) # find unique movieId number
length(unique(ratings_df$userId)) # find unique userId number
# check NA's in ratings data sets in specific field ----
na_rating <- ratings_df %>%
filter(is.na(ratings_df$movieId) |is.na(ratings_df$rating)|is.na(ratings_df$userId) )
na_rating # check NA's row - movies_d , rating and userId
# Find # of MovieId in both CSV files and then will be removed those movies in ratings_d.CSV which are not rated ----
movies_MovieIdCount <- length(unique(movies_dfc$movieId))
movies_MovieIdCount # check the movieId count in movies_d csv
ratings_MovieIdCount <- length(unique(ratings_df$movieId))
ratings_MovieIdCount # check the movieId count in ratings_d csv
# Find not rated rows in movieId and then removed rows from matrix_genre_Removerow ----
which((ratings_df$movieId %in% movies_dfc$movieId) == FALSE) # check which movieId is not noted in matrix
length(which((ratings_df$movieId %in% movies_dfc$movieId) == FALSE)) # count of movieId not rated
dim(ratings_df) # check dimension
length(unique(ratings_df$movieId)) # check length
ratings_df_removeRows <- ratings_df[-which((ratings_df$movieId %in% movies_dfc$movieId) == FALSE),] # removed not rated movieId
dim(ratings_df_removeRows) # check dimension after removing
length(unique(ratings_df_removeRows$movieId)) # check length after removing
rownames(ratings_df_removeRows) <- NULL
head(ratings_df_removeRows) #check rows
# store the final result of movies_dfc in new searchmovie_matrix.csv file for our shiny app----
write.csv(movies_dfc, "searchmovie_matrix.csv")
# store the final result of ratings_df_removeRows in new ratings_matrix.csv file for our shiny app----
write.csv(ratings_df_removeRows, "searchratings_matrix.csv")
# User-Based Collaborative Filtering Approach ----
# we are using the behavior of user's preference such as "genres"
# based on genre's items we recommends an items to similar users in the same
# group for views
# Create sparse matrix for recommendation. Rows = userId, Columns = movieId
ratings_matrix <- dcast(ratings_df_removeRows, userId~movieId, value.var = "rating", na.rm=FALSE) # movieId for x-axix and UserId for y-axix
ratings_matrix [1:10,1:10]# check 1-10 rows (userId) and columns (movieId)
dim(ratings_matrix) # check dimension of matrix
ncol(ratings_matrix) # check column number - actual movieId is 9690 so we need to remove first column userId
# convert dataframe into matrix
ratings_matrix <- as.matrix(ratings_matrix[,-1])# removing userid column and userId represent in matrix as Rows and movieId represent as Columns
ratings_matrix[1:10,1:10] # check rows
dim(ratings_matrix) # check dimension
# Convert rating matrix into a recommenderlab sparse matrix
ratings_matrix <- as(ratings_matrix, "realRatingMatrix")
ratings_matrix # check rating values
# recommendation model parameters use for our algorithm
recommender_model <- recommenderRegistry$get_entries(dataType = "realRatingMatrix")
names(recommender_model)
lapply(recommender_model, "[[", "description")
# look into user-based and item-based parameter for model preparation
recommender_model$IBCF_realRatingMatrix$parameters
recommender_model$UBCF_realRatingMatrix$parameters
# check the similarity between users or between items. prefer only one method while applying in model *cosine, pearson* and *jaccard*.
similarity_users <- similarity(ratings_matrix[1:4, ], method = "cosine", which = "users") # check 1 to 4 userid similarity
as.matrix(similarity_users)
image(as.matrix(similarity_users), main = "User to User similarity") # row and column represent to a user and each cell represent to the similarity, more red the cell = more similarity b/w users, diagonal is always red (each user itself comparing)
similarity_items <- similarity(ratings_matrix[, 1:4], method = "cosine", which = "items") # check 1 to 4 moviesid similarity
as.matrix(similarity_items)
image(as.matrix(similarity_items), main = "Movies to Movies similarity")
# find the rating count in each head based on total rating view 5,910,900
ratings_vector <- as.vector(ratings_matrix@data) # data shows no of rating
unique(ratings_vector) # unique rating values
ratingstable_vector <- table(ratings_vector) # put into table for each rating value count
ratingstable_vector # 0 rating values are so high 5,830,822 it represent missing values which will be removed from data sets
qplot(ratings_vector) +
ggtitle("Distribution of the ratings") # 0 rating values so high and now it removed from rating datasets
ratings_vector <- ratings_vector[ratings_vector != 0] # rating == 0 are missing values in rating datasets and now removed
ratings_vector <- factor(ratings_vector) # extract unique values of rating for graph
qplot(ratings_vector) +
ggtitle("Distribution of the ratings") # after removing 0 rating from graph. majority of rating values fall under > 3
# find top movies views in rating datasets
count_Permovie <- colCounts(ratings_matrix) # no of movie view for each movie
topmovies_views <- data.frame(movies_names = names(count_Permovie),
moviesviews = count_Permovie) # create movie view dataframe, assign movie view count as variable name
head(topmovies_views, 10) # check raw data
topmovies_views <- topmovies_views[order(topmovies_views$moviesviews, decreasing = TRUE),] # sort Desc
head(topmovies_views,10) # check the sorting
topmovies_views$title <- NA # create new variable called title and assigned NA
head(topmovies_views, 10) # check the rows
dim(topmovies_views) # check the dimension and rows
nrow(topmovies_views) # no of rows
head(movies_dfc) # few rows
for (r in 1:nrow(topmovies_views)){
topmovies_views[r,3] <- as.character(subset(movies_dfc, movies_dfc$movieId == topmovies_views[r,1])$title)
} # pick title from movies_dfc and added into topmovies_views
topmovies_views[1:6,] # check 1 to 6 rows
ggplot(topmovies_views[1:6, ], aes(x = title, y = moviesviews)) +
geom_bar(stat="identity") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
ggtitle("# of views - top movies")
# Average and Relevant movie rating distribution
avg_ratings <- colMeans(ratings_matrix) # average movie column rating in rating matrix
qplot(avg_ratings) +
stat_bin(binwidth = 0.1) +
ggtitle("Average movie rating distribution") # represent in graph, highest values fall btw 3 and 4 in average rating and 1, 2 and 5 have a fewest rating
avg_ratings_relevant <- avg_ratings[count_Permovie > 65] # set minimum criteria 50 view per movie out of 1302 views.
qplot(avg_ratings_relevant) +
stat_bin(binwidth = 0.1) +
ggtitle(paste("Average relevant movie rating distribution")) # represent in graph, people rated the movies b/w 3 and 4.5
# create Heatmap graph for rating matrix ----
# row represent userId, column represent movieId and cell represent to ratings
image(ratings_matrix, main = "Rating Matrix - Heatmap") # difficult to read the rating dimensions
image(ratings_matrix[1:20, 1:25], main = "Rating Matrix - Heatmap 20 rows and 25 columns") # close look of 20 rows and 25 columns
# Now I set the criteria to shorten rating data set because some user saw more movie and but not rated or some movie seen by many users but not rated and vice versa
min_nof_movies <- quantile(rowCounts(ratings_matrix), 0.98) # set the min values of movie per user and apply 0.98% probability out of 1 , row represent user
min_nof_movies
min_nof_users <- quantile(colCounts(ratings_matrix), 0.98) # set the min values of user per movie and apply 0.98% probability out of 1 , column represent movie
min_nof_users
image(ratings_matrix[rowCounts(ratings_matrix) > min_nof_movies,
colCounts(ratings_matrix) > min_nof_users],
main = "Heatmap - top users and movies based on 98% probability") # apply user and movies matching criteria, dark represent high-rated movies and user also gave high ratings
# customize our rating matrix data set ----
# two steps 1) select more relevant data (user and movies) 2) Normalize the data
# 1) select more relevant data (user and movies)
# assume 70 (12% of total user 610) minimum number of users rated per movie and 65 (5% of total views 1302) minimum views number per movie
movies_ratings <- ratings_matrix[rowCounts(ratings_matrix) > 70,
colCounts(ratings_matrix) > 65]
movies_ratings # compared to 610 user x 9690 movies with total ratings 100,789
# now select top 98% of users and movies in the next rating matrix
Newmin_nof_movies <- quantile(rowCounts(movies_ratings), 0.98) # set the min values of movie per user
Newmin_nof_users <- quantile(colCounts(movies_ratings), 0.98) # set the min values of user per movies
image(movies_ratings[rowCounts(movies_ratings) > Newmin_nof_movies,
colCounts(movies_ratings) > Newmin_nof_users],
main = "Heatmap - top users and movies (Revised) based on 98% probability") # present in graph
avg_ratings_per_user <- rowMeans(movies_ratings) # average row user rating in rating matrix
qplot(avg_ratings_per_user) + stat_bin(binwidth = 0.1) +
ggtitle("Average Rating per user- Distribution") # average rating per user varies a lot
# 2) Normalize the data
# To remove the bias factor in movies rating as user gave, I normalized data to ensure that overall average to mean is Zero.
movies_ratings_normalized <- normalize(movies_ratings)
sum(rowMeans(movies_ratings_normalized) > 0.00001) # check to see sum of user average rating should be zero.
image(movies_ratings_normalized[rowCounts(movies_ratings_normalized) > Newmin_nof_movies,
colCounts(movies_ratings_normalized) > Newmin_nof_users],
main = "Heatmap - top users and movies (Normalized") # present in graph for top user and movies, some cell shows red and blue color, however sum of average rating is ZERO
# Developing Training / Testing data sets ----
# In our recommendation system, we used collaborative filtering approach
# Basic concepts is user's collaborating to each other to recommend other items
# key Algorithm points are 1) similarity rating between two items by similar users 2) Identify each item of K (neighbor) most similar items
# 3) Identify each user of similar items for each users
# I used 80% as training data and 20% used as testing data in rating matrix
sampled_moviesratings <- sample(x = c(TRUE, FALSE),
size = nrow(movies_ratings),
replace = TRUE,
prob = c(0.8, 0.2)) # 80% training and 20% testing
Train_data <- movies_ratings[sampled_moviesratings, ] # create training set
Train_data # check the rows and columns
Test_data <- movies_ratings[!sampled_moviesratings, ] # create testing set
Test_data # check the rows and columns
# Create recommendation model -----
# we used UBCF (user-based) model and IBCF (item-based) model as comparison
# in UBCF model parameter, nn = 30 (already defined, # of items to compute similarity ) and
# method = Cosine(by Default) as alternative "Pearson" will be used
# recommender_models <- recommenderRegistry$get_entries(dataType ="realRatingMatrix") (already mentioned in earlier steps)
# recommender_models$IBCF_realRatingMatrix$parameters (already mentioned in earlier steps)
Model_Recommendation_IBCF <- Recommender(data = Train_data, method = "IBCF",
parameter = list(method="Cosine", normalize = "Z-score", k = 30)) # IBCF recommendation model
Model_Recommendation_IBCF # check recommendation information
class(Model_Recommendation_IBCF) # check class of recommendation model
# exploring recommender model of IBCF  ----
model_info <- getModel(Model_Recommendation_IBCF)
model_info$description # model description
model_info$k # k = 30
class(model_info$sim) # has similarity matrix content information
dim(model_info$sim) # check the dimension of similarity matrix
no_items <- 20 # first 20 rows and first 20 columns
image(model_info$sim[1:no_items, 1:no_items],
main = "Heatmap - first 20 rows and 20 columns") # represent in graph, In first 20 items many values are ZERO however few items in respect of K (30) neighbor element
# their values are > ZERO which means that matrix are not fully symmetric.
row_sums_matrix <- rowSums(model_info$sim > 0) # checking sum of rows in the similarity matrix above ZERO
table(row_sums_matrix) # check in table
col_sums_matrix <- colSums(model_info$sim > 0) # checking sum of columns in the similarity matrix above ZERO
table(col_sums_matrix) # check in table
qplot(col_sums_matrix) + stat_bin(binwidth = 1) + ggtitle("Count Column - Distribution") # present in graph shows that few movies are similar to other items
# check 1 to 6 most element movies
targetCHK_list <- order(col_sums_matrix, decreasing = TRUE)[1:6] # sort in desc
targetCHK_list # list movie id counts
list_Movies <- as.integer(rownames(model_info$sim)[targetCHK_list]) # assign list of movie's count and extract movid id
list_Movies # list movie id
for (i in 1:6){
list_Movies[i] <- as.character(subset(movies_dfc,movies_dfc$movieId == list_Movies[i])$title) # pick movie id title from movies_dfc datasets
}
list_Movies # print 1 to 6 top movie titles
# Applying recommender model IBCF ----
# let assume 10 number of movies recommend to each user based on 20 % of testing dataset
# recommder model, first start extracting movies rating of each movies and then find similar movies
# in the similarity matrix of movies for recommendation to users
no_recommendedMovies <- 10 # max 10 movies recommend to each user
predicted_model_IBCF <- predict(object = Model_Recommendation_IBCF, newdata = Test_data,
n = no_recommendedMovies) # apply predication
predicted_model_IBCF # check predication values
predicted_model_IBCF_user_1 <- predicted_model_IBCF@items[[1]] # extract 1-10 movies items from predication model for 1st user
predicted_model_IBCF_user_1 # showing 1-10 movie items for user 1
predicted_model_IBCF_movie_user_1 <- predicted_model_IBCF@itemLabels[predicted_model_IBCF_user_1] # pick movie id based on 1-10 predication
predicted_model_IBCF_movie_user_1 # showing 1-10 movie items for user 1
predicted_model_IBCF_movie_user_2 <- predicted_model_IBCF_movie_user_1
for (i in 1:10){
predicted_model_IBCF_movie_user_2[i] <- as.character(subset(movies_dfc,
movies_dfc$movieId == predicted_model_IBCF_movie_user_1[i])$title)
} # pick movie title from movie_dfc data set for 10 movie items
predicted_model_IBCF_movie_user_2 # generate 1-10 movies list for user 2
Recommder_matrix_IBCF <- sapply(predicted_model_IBCF@items,
function(x){ as.integer(colnames(movies_ratings)[x]) }) # create matrix with the recommendations for each user
dim(Recommder_matrix_IBCF) # check dimension
Recommder_matrix_IBCF[,1:4] # 1-4 user, column = user and row = movies items (1-10 movies)
# Recommended movies based on distribution of 1-10 movies items
noof_items <- factor(table(Recommder_matrix_IBCF))
char_title <- "IBCF - Distribution by items"
qplot(noof_items) + ggtitle(char_title) # present in graph
noof_items_sorted <- sort(noof_items, decreasing = TRUE) # sorting in desc
noof_items_4top <- head(noof_items_sorted, n = 4) # top 4 assigned in another variable
table_4top <- data.frame(as.integer(names(noof_items_4top)),
noof_items_4top) # convert into dataframe
table_4top # show top 4 values
for (i in 1:4){
table_4top[i,1] <- as.character(subset(movies_dfc,
movies_dfc$movieId == table_4top[i,1])$title)
} # pick movie title from movie_dfc data set
colnames(table_4top) <- c("title", "# items") # assign colum names
head(table_4top) # check rows for 4 top list
# User Based Collaborative Filtering system ----
# similar user identified and then item rated by similar user is recommended
# similar is measure through cosine and correlation method (any one)
# k- nearest-neighbors identify
Model_Recommendation_UBCF <- Recommender(data = Train_data, method = "UBCF",
parameter = list(method="Cosine", nn = 30, normalize = "Z-score", minRating=3)) # UBCF recommendation model
Model_Recommendation_UBCF # check recommendation information
class(Model_Recommendation_UBCF) # check class of recommendation model
model_info_UBCF <- getModel(Model_Recommendation_UBCF)
model_info_UBCF$description # model description
model_info_UBCF$nn # nn = 30
dim(model_info_UBCF$data) # check the dimension of similarity matrix
no_recommendedMovies <- 10 # max 10 movies recommend to each user
predicted_model_UBCF <- predict(object = Model_Recommendation_UBCF, newdata = Test_data,
n = no_recommendedMovies) # apply predication
predicted_model_UBCF # check predication values
Recommder_matrix_UBCF <- sapply(predicted_model_UBCF@items,
function(x){ as.integer(colnames(movies_ratings)[x]) }) # create matrix with the recommendations for each user
dim(Recommder_matrix_UBCF) # check dimension
Recommder_matrix_UBCF[,1:4] # 1-4 user, column = user and row = movies items (1-10 movies)
noof_items <- factor(table(Recommder_matrix_UBCF))
char_title <- "UBCF - Distribution by items"
qplot(noof_items) + ggtitle(char_title) # present in graph
noof_items_sorted <- sort(noof_items, decreasing = TRUE) # sorting in desc
noof_items_4top <- head(noof_items_sorted, n = 4) # top 4 assigned in another variable
table_4top <- data.frame(as.integer(names(noof_items_4top)),
noof_items_4top) # convert into dataframe
table_4top # show top 4 values
for (i in 1:4){
table_4top[i,1] <- as.character(subset(movies_dfc,
movies_dfc$movieId == table_4top[i,1])$title)
} # pick movie title from movie_dfc data set
colnames(table_4top) <- c("title", "# items") # assign column names
head(table_4top) # check rows for 4 top list
# While comparing both IBCF and UBCF, we found that distribution of movie count is higher in UBCF (Average 17 movie viewed) as
# compared to IBCF (Average 11 movie viewed)
# Recommended System Evaluation ----
# three way to evaluate the model. Choose best performing model among them and then optimize parameter if needed
# 1) split the data into training (80%) and testing (20%)
# 2) bootstrapping
# 3) k-fold
# 1) splitting data set
min(rowCounts(movies_ratings)) # find minimum number of items rated by user to ensure item is rated
training_Percentage <- 0.8
items_to_recommend <- 10 # # of items to be recommended
ratings_threshold <- 3.5 # set minimum Rating threshold consider to be good
noof_evaluation <- 1 # set 1 time to run evaulation
evaluation_Matrix <- evaluationScheme(data = movies_ratings,method = "split",
train = training_Percentage, given = items_to_recommend,
goodRating = ratings_threshold, k = noof_evaluation) # system evaluation
evaluation_Matrix # show evaluation parameter
getData(evaluation_Matrix, "train") # training matrix information
getData(evaluation_Matrix, "known") # set with the items used to build the recommendations
getData(evaluation_Matrix, "unknown") # set with the items used to test the recommendations
qplot(rowCounts(getData(evaluation_Matrix, "unknown")), xlab="unknown", ylab="user") +
geom_histogram(binwidth = 10) +
ggtitle("unknown items by the users") # present in graph shows about majority of unknown items by user
# 2) bootstrapping the data
# In this splitting method, possibility is that same user may be a sample user in test set based on the same size of training data set and other parameters
evaluation_Matrix <- evaluationScheme(data = movies_ratings, method = "bootstrap",
train = training_Percentage, given = items_to_recommend,
goodRating = ratings_threshold, k = noof_evaluation) # system evaluation
evaluation_Matrix # show evaluation parameter
getData(evaluation_Matrix, "train") # training matrix information
getData(evaluation_Matrix, "known") # set with the items used to build the recommendations
getData(evaluation_Matrix, "unknown") # set with the items used to test the recommendations
qplot(rowCounts(getData(evaluation_Matrix, "unknown")), xlab="unknown", ylab="user") +
geom_histogram(binwidth = 10) +
ggtitle("unknown items by the users") # present in graph shows about majority of unknown items by user
train_table <- table(evaluation_Matrix@runsTrain[[1]]) # generate training table
noof_repetitions <- factor(as.vector(train_table))
qplot(noof_repetitions, xlab="repetitions", ylab="user") +
ggtitle("# of repetitions in the training set") # mostly user are repeated in training set as a sample
# 3) k-fold (cross-validation)
# more accurate approach using average (weight) accuracy.
# Data is split into different chunk. take out testing data from one chunk
# and then evaluate the accuracy. same thing for another chunk. finally compute
# all chunk accuracy by using average (weight) method.
noof_fold <- 5 # set the K fold parameter
evaluation_Matrix <- evaluationScheme(data = movies_ratings, method = "cross-validation",
given = items_to_recommend,
goodRating = ratings_threshold,
k = noof_fold) # system evaluation
evaluation_Matrix # show evaluation parameter
getData(evaluation_Matrix, "train") # training matrix information
getData(evaluation_Matrix, "known") # set with the items used to build the recommendations
getData(evaluation_Matrix, "unknown") # set with the items used to test the recommendations
qplot(rowCounts(getData(evaluation_Matrix, "unknown")), xlab="unknown", ylab="user") +
geom_histogram(binwidth = 10) +
ggtitle("unknown items by the users") # present in graph shows about majority of unknown i
size_sets <- sapply(evaluation_Matrix@runsTrain, length)
size_sets # using 5-fold method, we get 5 sets of the same size
# Ratings Evaluation
# As K-fold approach is accurate then we build UBCF (User_based) model and find prediction ratings
evaluation_Matrix <- evaluationScheme(data = movies_ratings,
method = "cross-validation",
given = items_to_recommend,
goodRating = ratings_threshold,
k = noof_fold) # system evaluation
evaluate_model <- "UBCF" # Utem-based collaborative filtering
parameters_model <- NULL
Model_Recommendation_Evaluation <- Recommender(data = getData(evaluation_Matrix, "train"),
method = evaluate_model,
parameter = parameters_model) # Model recommendation based on K-fold
Model_Recommendation_Evaluation # check recommendation information
class(Model_Recommendation_Evaluation) # check class of recommendation model
no_recommendedMovies <- 10 # max 10 movies recommend to each user
predicted_model_Evaluation <- predict(object = Model_Recommendation_Evaluation,
newdata = getData(evaluation_Matrix, "known"),
type = "ratings",
n = no_recommendedMovies) # apply predication
predicted_model_Evaluation # check predication values
qplot(rowCounts(predicted_model_Evaluation)) +
geom_histogram(binwidth = 10) +
ggtitle("Distribution of movies per user") # movie per user in predicted ratings
accuracy_Evaluation <- calcPredictionAccuracy(x = predicted_model_Evaluation,
data = getData(evaluation_Matrix, "unknown"),
byUser = TRUE) # apply rating accuracy for each user, RMSE should be lower which mean that model is better fit towards prediction values
head(accuracy_Evaluation) # check the row
qplot(accuracy_Evaluation[, "RMSE"]) +
geom_histogram(binwidth = 0.1) +
ggtitle("Distribution of the RMSE by user") # Root mean square errors
accuracy_Evaluation <- calcPredictionAccuracy(x = predicted_model_Evaluation,
data = getData(evaluation_Matrix, "unknown"),
byUser = FALSE) # apply rating accuracy for each user, RMSE should be lower which mean that model is better fit towards prediction values
head(accuracy_Evaluation) # check accuracy of whole model
# Evaluating the recommendations
# another way to measure the accuracy is positive rating.
# and set the N (# of items) in parameters to evaluate performance
Model_results <- evaluate(x = evaluation_Matrix,
method = evaluate_model,
n = seq(10, 100, 10))
head(getConfusionMatrix(Model_results)[[1]]) # get confusion Matrix
columns_to_sum <- c("TP", "FP", "FN", "TN") # column name assigned
indices_summed <- Reduce("+", getConfusionMatrix(Model_results))[, columns_to_sum]
head(indices_summed)
plot(Model_results, annotate = TRUE, main = "ROC curve") # Plot ROC graph
plot(Model_results, "prec/rec", annotate = TRUE, main = "Precision-recall") # checking precision /recall curves [small % of movie recommended then precision is lower and higher % of rated movies recommended than recall is higher]
# Comparing all recommendation models ----
# pick all recommendation model and then set N = # of recommend movies in sequence (10, 100, 10)
evaluate_model_Complex <- list(
IBCF_cos = list(name = "IBCF",
param = list(method = "cosine", normalize = "Z-score" )), # using the Cosine as the distance function
IBCF_Pearson = list(name = "IBCF",
param = list(method = "pearson", normalize = "Z-score" )), # using the Pearson correlation as the distance function
UBCF_cos = list(name = "UBCF",
param = list(method = "cosine", normalize = "Z-score")), # using the Cosine as the distance function
UBCF_Person = list(name = "UBCF",
param = list(method = "pearson", normalize = "Z-score" )), # using the Pearson correlation as the distance function
random = list(name = "RANDOM", param= list(normalize = "Z-score")) #Random recommendations to have a base line
)
noof_recommendations <- c(1, 5, seq(10, 100, 10))
list_results <- evaluate(x = evaluation_Matrix,
method = evaluate_model_Complex,
n = noof_recommendations) # compare all model
sapply(list_results, class) == "evaluationResults"
avg_matrices <- lapply(list_results, avg)
head(avg_matrices$UBCF_Person[, 5:8])
# Identifying the most suitable model ----
# compare all model graph by displaying ROC and Precision/Recall curves
# chart shows highest ROC is UBCF with Pearson technique.
plot(list_results, annotate = 1, legend = "topleft")
title("ROC curve")
plot(list_results, "prec/rec", annotate = 1, legend = "bottomright")
title("Precision-recall")
# Optimizing a numeric parameter ----
# Using UBCF method I optimized values by selecting pearson method, set the K-closes items range from 5 and 50
K_closestItems <- c(5, 10, 20, 30, 40, 50)
models_to_evaluate <- lapply(K_closestItems, function(k){
list(name = "UBCF",
param = list(method = "pearson", normalize = "Z-score", k = k))
})
names(models_to_evaluate) <- paste0("UBCF_k_", K_closestItems)
# same method to find the different values of K-closest values
noof_recommendations <- c(1, 5, seq(10, 100, 10))
list_results <- evaluate(x = evaluation_Matrix, method = models_to_evaluate,
n = noof_recommendations) # compare all model
plot(list_results, annotate = 1, legend = "topleft")
title("ROC curve")
plot(list_results, "prec/rec", annotate = 1, legend = "bottomright")
title("Precision-recall")
# Based on the ROC curve's plot, the k having the same values (1,5... ) in ROC and Recalls/Precision so we set K to 10.
# Load the data sets from CSV file ----
movies_d<-read.csv("movies.csv",header=TRUE)
if(! "arules" %in% installed.packages()) install.packages("arules", depend = TRUE)
library(arules)
if(! "arulesViz" %in% installed.packages()) install.packages("arulesViz", depend = TRUE)
library(arulesViz)
if(! "recommenderlab" %in% installed.packages()) install.packages("recommenderlab", depend = TRUE)
library("recommenderlab")
if(! "reshape2" %in% installed.packages()) install.packages("reshape2", depend = TRUE)
library("reshape2")
if(! "data.table" %in% installed.packages()) install.packages("data.table", depend = TRUE)
library(data.table)
if(! "ggplot2" %in% installed.packages()) install.packages("ggplot2", depend = TRUE)
library(ggplot2)
library(rmarkdown)
# Load the data sets from CSV file ----
movies_d<-read.csv("movies.csv",header=TRUE)
ratings_d<-read.csv("ratings.csv",header=TRUE)
# check the structure of csv files ----
str(movies_d)
str(ratings_d)
# Check the data sets dimension and summary of statistic ----
dim(movies_d)
summary(movies_d)
dim(ratings_d)
summary(ratings_d)
# check first 10 rows of data sets ----
head(movies_d, 10)
head(ratings_d, 10)
# checking hig-level behavior pattern of userId, moveId and ratings ----
hist(ratings_d$userId) # check the high-level pattern of userId
ratings_histogram_UID <- ratings_d %>%
mutate(userId = factor(userId)) %>%
group_by(userId) %>%   # group by userId
summarize(count_MovieId = round(length(movieId), 2)) %>% # count by movieId
arrange(desc(count_MovieId))
ratings_histogram_UID [1:10,] # showing in group values
ggplot(ratings_histogram_UID[1:10,], aes(x = userId, y = count_MovieId)) +
geom_bar(stat = "identity") + labs(title =" Top MovieId Sort by Userid", x = "UserId", y = "MovieId(Count)") # visualization of MoveId
hist(ratings_d$rating) # check the high-level pattern of user's ratings
ratings_histogram_Rat <- ratings_d %>%
mutate(rating = factor(rating)) %>%
group_by(rating) %>%   # group by rating
summarize(count_UserId = round(length(userId), 2)) %>% # count by userId
arrange(desc(count_UserId))
ratings_histogram_Rat # showing in rating values
ggplot(ratings_histogram_Rat, aes(x = rating, y = count_UserId)) +
geom_bar(stat = "identity") + labs(title =" Top UserId Sort by Rating", x = "Rating Threshold", y = "UserId(Count)") # visualization of Rating
hist(ratings_d$movieId) # check the high-level pattern of movieId
hist(ratings_d$movieId[1:200]) # checking 1-200 movies id
# Load the packages ----
install.packages("pacman")
install.packages("pacman")
install.packages("pacman")
setwd("C:/Users/asamnani/Desktop/PC Data/PC Data/AI Course/York University/Course 2/Week 1/Assignment 1/shinyweblab1")
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
